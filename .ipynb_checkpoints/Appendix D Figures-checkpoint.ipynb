{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d67c3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import os\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.patches import Patch\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib as mpl\n",
    "import matplotlib.ticker as ticker\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Configure font sizes.\n",
    "TICK_SIZE = 6\n",
    "SMALL_SIZE = 6\n",
    "MEDIUM_SIZE = 8\n",
    "BIGGER_SIZE = 11\n",
    "plt.rc(\"font\", size=SMALL_SIZE)  # controls default text sizes\n",
    "plt.rc(\"axes\", titlesize=MEDIUM_SIZE)  # fontsize of the axes title\n",
    "plt.rc(\"axes\", labelsize=MEDIUM_SIZE)  # fontsize of the x and y labels\n",
    "plt.rc(\"xtick\", labelsize=TICK_SIZE)  # fontsize of the tick labels\n",
    "plt.rc(\"ytick\", labelsize=TICK_SIZE)  # fontsize of the tick labels\n",
    "plt.rc(\"legend\", fontsize=SMALL_SIZE)  # legend fontsize\n",
    "plt.rc(\"figure\", titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "\n",
    "MARKERSIZE = 3\n",
    "LINEWIDTH = 0.5\n",
    "plt.rc(\"lines\", markersize=MARKERSIZE, linewidth=LINEWIDTH)\n",
    "plt.rc(\"grid\", linewidth=0.5)\n",
    "plt.rc(\"grid\", alpha=0.5)\n",
    "\n",
    "# colorblind friendly colors: https://gist.github.com/thriveth/8560036\n",
    "colors = [\"#377eb8\", \"#ff7f00\", \"#4daf4a\", \"#f781bf\", \"#a65628\", \"#984ea3\", \"#999999\", \"#e41a1c\", \"#dede00\"]\n",
    "\n",
    "# how many questions does each dataset have?\n",
    "N_QUESTIONS = {\"bbh+gpqa+ifeval+math+musr\" : 9574, \"mmlu-pro\" : 12032}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5812ff0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in our log files\n",
    "best_baseline_summary = pd.read_csv(\"logs/final/cleaned/best_baseline_summary.csv\")\n",
    "best_ablation_summary = pd.read_csv(\"logs/final/cleaned/best_ablation_summary.csv\")\n",
    "faq_summary = pd.read_csv(\"logs/final/cleaned/faq_summary.csv\")\n",
    "uniform_summary = pd.read_csv(\"logs/final/cleaned/uniform_summary.csv\")\n",
    "\n",
    "# get our 10x budget values\n",
    "budgets = best_baseline_summary.prop_budget.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ce2617",
   "metadata": {},
   "source": [
    "# ESS of FAQ, Best Baseline, and Uniform on the two datasets under ultra-sparse data conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94af455c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can put coverages in the appendix: let's just do a 2x2 of dataset x missingness-setting\n",
    "fig, ax = plt.subplots(2, 4, dpi=400, figsize=(6.5, 3.0), sharex=\"row\")\n",
    "\n",
    "# go through our missingness-settings\n",
    "for j, missingness_setting in enumerate([(800, 0.1), (200, 0.1), (50, 0.1), (0.0, 1e-3)]):\n",
    "    \n",
    "    # unpack the setting\n",
    "    n_full_obs, mcar_obs_prob = missingness_setting\n",
    "    \n",
    "    # go thru the datasets\n",
    "    for i, dataset in enumerate([\"mmlu-pro\", \"bbh+gpqa+ifeval+math+musr\"]):\n",
    "        \n",
    "        # get our data\n",
    "        q_faq = faq_summary.query(\n",
    "            f\"dataset == '{dataset}' and n_full_obs == {n_full_obs} and mcar_obs_prob == {mcar_obs_prob}\")\n",
    "        q_baseline = best_baseline_summary.query(\n",
    "            f\"dataset == '{dataset}' and n_full_obs == {n_full_obs} and mcar_obs_prob == {mcar_obs_prob}\")\n",
    "        q_uniform = uniform_summary.query(f\"dataset == '{dataset}'\")\n",
    "        \n",
    "        # beautify\n",
    "        ax[i, j].grid()\n",
    "        \n",
    "        # how many questions do we have?\n",
    "        N_QUESTIONS = 12032 if dataset == \"mmlu-pro\" else 9574\n",
    "        \n",
    "        # label the subplot if necessary\n",
    "        if j == 0:\n",
    "            ax[i, j].set_ylabel(\n",
    "                {\"mmlu-pro\" : \"MMLU-Pro\", \"bbh+gpqa+ifeval+math+musr\" : \"BBH+GPQA+IFEval\\n+MATH+MuSR\"}[dataset])\n",
    "        if i == 0:\n",
    "            mcar_obs_prob_perc = mcar_obs_prob*100 if\\\n",
    "            int(mcar_obs_prob*100) != mcar_obs_prob*100 else int(mcar_obs_prob*100)\n",
    "            ax[i, j].set_title(\n",
    "                f\"{int(n_full_obs)} Fully-Obs. Rows\\n\" +\\\n",
    "                f\"{mcar_obs_prob_perc}% Obs. Entries\")\n",
    "        if i == 1:\n",
    "            ax[i, j].set_xlabel(f\"Budget\")\n",
    "        \n",
    "        # FAQ results\n",
    "        ax[i, j].errorbar(\n",
    "            q_faq.prop_budget * N_QUESTIONS, q_faq.ess_multiplier * budgets * N_QUESTIONS, \n",
    "            yerr=q_faq.ess_multiplier_serr * budgets * N_QUESTIONS, marker=\"o\", \n",
    "            capsize=MARKERSIZE, capthick=1.0, color=colors[0])\n",
    "            \n",
    "        # Best baseline results\n",
    "        ax[i, j].errorbar(\n",
    "            q_baseline.prop_budget * N_QUESTIONS, q_baseline.ess_multiplier * budgets * N_QUESTIONS, \n",
    "            yerr=q_baseline.ess_multiplier_serr * budgets * N_QUESTIONS, marker=\"x\", \n",
    "            capsize=MARKERSIZE, capthick=1.0, color=colors[1])\n",
    "        \n",
    "        # uniform results\n",
    "        ax[i, j].errorbar(\n",
    "            q_uniform.prop_budget * N_QUESTIONS, q_uniform.ess_multiplier * budgets * N_QUESTIONS, \n",
    "            yerr=q_uniform.ess_multiplier_serr * budgets * N_QUESTIONS, marker=\"^\", \n",
    "            capsize=MARKERSIZE, capthick=1.0, color=colors[2])\n",
    "        \n",
    "# custom legend\n",
    "handles = [\n",
    "    Line2D([], [], marker=\"o\", color=colors[0], label=\"FAQ\"),\n",
    "    Line2D([], [], marker=\"x\", color=colors[1], label=\"Best Baseline Per Budget\"),\n",
    "    Line2D([], [], marker=\"^\", color=colors[2], label=\"Uniform\")\n",
    "]\n",
    "fig.legend(handles=handles, ncol=3, loc=\"lower center\", bbox_to_anchor=(0.5, -0.07))\n",
    "\n",
    "# sharing axes\n",
    "ax[0, 1].sharey(ax[0, 0]); ax[0, 2].sharey(ax[0, 0])\n",
    "ax[1, 1].sharey(ax[1, 0]); ax[1, 2].sharey(ax[1, 0])\n",
    "\n",
    "# beautify\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"appendix_figures/1_ess_sparsity-settings_both-datasets.pdf\", facecolor=\"white\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b995ecc",
   "metadata": {},
   "source": [
    "# Coverage of FAQ, Best Baseline, and Uniform on the two datasets under ultra-sparse data conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb2ff8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can put coverages in the appendix: let's just do a 2x2 of dataset x missingness-setting\n",
    "fig, ax = plt.subplots(2, 4, dpi=400, figsize=(6.5, 3.0), sharex=\"row\", sharey=True)\n",
    "\n",
    "# go through our missingness-settings\n",
    "for j, missingness_setting in enumerate([(800, 0.1), (200, 0.1), (50, 0.1), (0.0, 1e-3)]):\n",
    "    \n",
    "    # unpack the setting\n",
    "    n_full_obs, mcar_obs_prob = missingness_setting\n",
    "    \n",
    "    # go thru the datasets\n",
    "    for i, dataset in enumerate([\"mmlu-pro\", \"bbh+gpqa+ifeval+math+musr\"]):\n",
    "        \n",
    "        # get our data\n",
    "        q_faq = faq_summary.query(\n",
    "            f\"dataset == '{dataset}' and n_full_obs == {n_full_obs} and mcar_obs_prob == {mcar_obs_prob}\")\n",
    "        q_baseline = best_baseline_summary.query(\n",
    "            f\"dataset == '{dataset}' and n_full_obs == {n_full_obs} and mcar_obs_prob == {mcar_obs_prob}\")\n",
    "        q_uniform = uniform_summary.query(f\"dataset == '{dataset}'\")\n",
    "        \n",
    "        # beautify\n",
    "        ax[i, j].grid()\n",
    "        ax[i, j].set_ylim(bottom=0.85, top=1.0)\n",
    "        ax[i, j].axhline(y=0.95, color=\"black\", linestyle=\"--\")\n",
    "        \n",
    "        # how many questions do we have?\n",
    "        N_QUESTIONS = 12032 if dataset == \"mmlu-pro\" else 9574\n",
    "        \n",
    "        # label the subplot if necessary\n",
    "        if j == 0:\n",
    "            ax[i, j].set_ylabel(\n",
    "                {\"mmlu-pro\" : \"MMLU-Pro\", \"bbh+gpqa+ifeval+math+musr\" : \"BBH+GPQA+IFEval\\n+MATH+MuSR\"}[dataset])\n",
    "        if i == 0:\n",
    "            mcar_obs_prob_perc = mcar_obs_prob*100 if\\\n",
    "            int(mcar_obs_prob*100) != mcar_obs_prob*100 else int(mcar_obs_prob*100)\n",
    "            ax[i, j].set_title(\n",
    "                f\"{int(n_full_obs)} Fully-Obs. Rows\\n\" +\\\n",
    "                f\"{mcar_obs_prob_perc}% Obs. Entries\")\n",
    "        if i == 1:\n",
    "            ax[i, j].set_xlabel(f\"Budget\")\n",
    "        \n",
    "        # FAQ results\n",
    "        ax[i, j].errorbar(\n",
    "            q_faq.prop_budget * N_QUESTIONS, q_faq.coverage, \n",
    "            yerr=q_faq.coverage_serr, marker=\"o\", \n",
    "            capsize=MARKERSIZE, capthick=1.0, color=colors[0])\n",
    "            \n",
    "        # Best baseline results\n",
    "        ax[i, j].errorbar(\n",
    "            q_baseline.prop_budget * N_QUESTIONS, q_baseline.coverage, \n",
    "            yerr=q_baseline.coverage_serr, marker=\"x\", \n",
    "            capsize=MARKERSIZE, capthick=1.0, color=colors[1])\n",
    "        \n",
    "        # uniform results\n",
    "        ax[i, j].errorbar(\n",
    "            q_uniform.prop_budget * N_QUESTIONS, q_uniform.coverage, \n",
    "            yerr=q_uniform.coverage_serr, marker=\"^\", \n",
    "            capsize=MARKERSIZE, capthick=1.0, color=colors[2])\n",
    "        \n",
    "# custom legend\n",
    "handles = [\n",
    "    Line2D([], [], marker=\"o\", color=colors[0], label=\"FAQ\"),\n",
    "    Line2D([], [], marker=\"x\", color=colors[1], label=\"Best Baseline Per Budget\"),\n",
    "    Line2D([], [], marker=\"^\", color=colors[2], label=\"Uniform\"),\n",
    "    Line2D([], [], color=\"black\", linestyle=\"--\", label=\"95% Coverage (Bottom Subplots)\")\n",
    "]\n",
    "fig.legend(handles=handles, ncol=4, loc=\"lower center\", bbox_to_anchor=(0.5, -0.07))\n",
    "\n",
    "# beautify\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"appendix_figures/2_coverage_sparsity-settings_both-datasets.pdf\", facecolor=\"white\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c6ead1",
   "metadata": {},
   "source": [
    "# Widths of FAQ, Best Baseline, and Uniform on the two datasets under ultra-sparse data conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc3676b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can put coverages in the appendix: let's just do a 2x2 of dataset x missingness-setting\n",
    "fig, ax = plt.subplots(2, 5, dpi=400, figsize=(6.5, 3.0), sharex=\"row\", sharey=True)\n",
    "\n",
    "# go through our missingness-settings\n",
    "for j, missingness_setting in enumerate([(None, 1.0), (800, 0.1), (200, 0.1), (50, 0.1), (0.0, 1e-3)]):\n",
    "    \n",
    "    # unpack the setting\n",
    "    n_full_obs, mcar_obs_prob = missingness_setting\n",
    "    \n",
    "    # go thru the datasets\n",
    "    for i, dataset in enumerate([\"mmlu-pro\", \"bbh+gpqa+ifeval+math+musr\"]):\n",
    "        \n",
    "        # get our data\n",
    "        if n_full_obs is not None:\n",
    "            q_faq = faq_summary.query(\n",
    "                f\"dataset == '{dataset}' and n_full_obs == {n_full_obs} and mcar_obs_prob == {mcar_obs_prob}\")\n",
    "            q_baseline = best_baseline_summary.query(\n",
    "                f\"dataset == '{dataset}' and n_full_obs == {n_full_obs} and mcar_obs_prob == {mcar_obs_prob}\")\n",
    "            q_uniform = uniform_summary.query(f\"dataset == '{dataset}'\")\n",
    "        else:\n",
    "            q_faq = faq_summary.query(\n",
    "                f\"dataset == '{dataset}' and mcar_obs_prob == {mcar_obs_prob}\")\n",
    "            q_baseline = best_baseline_summary.query(\n",
    "                f\"dataset == '{dataset}' and mcar_obs_prob == {mcar_obs_prob}\")\n",
    "            q_uniform = uniform_summary.query(f\"dataset == '{dataset}'\")\n",
    "        \n",
    "        # beautify\n",
    "        ax[i, j].grid(); ax[i, j].set_yscale(\"log\")\n",
    "        ax[i, j].set_yticks([0.025, 0.05, 0.1])\n",
    "        ax[i, j].set_yticklabels([0.025, 0.05, 0.1])\n",
    "        \n",
    "        # how many questions do we have?\n",
    "        N_QUESTIONS = 12032 if dataset == \"mmlu-pro\" else 9574\n",
    "        \n",
    "        # label the subplot if necessary\n",
    "        if j == 0:\n",
    "            ax[i, j].set_ylabel(\n",
    "                {\"mmlu-pro\" : \"MMLU-Pro\", \"bbh+gpqa+ifeval+math+musr\" : \"BBH+GPQA+IFEval\\n+MATH+MuSR\"}[dataset])\n",
    "        if i == 0:\n",
    "            mcar_obs_prob_perc = mcar_obs_prob*100 if\\\n",
    "            int(mcar_obs_prob*100) != mcar_obs_prob*100 else int(mcar_obs_prob*100)\n",
    "            if n_full_obs is not None:\n",
    "                ax[i, j].set_title(\n",
    "                    f\"{int(n_full_obs)} Fully-Obs. Rows\\n\" +\\\n",
    "                    f\"{mcar_obs_prob_perc}% Obs. Entries\", fontsize=BIGGER_SIZE - 4)\n",
    "            else:\n",
    "                ax[i, j].set_title(\"Fully-Observed\", fontsize=BIGGER_SIZE - 4)\n",
    "        if i == 1:\n",
    "            ax[i, j].set_xlabel(f\"Budget\", fontsize=BIGGER_SIZE - 4)\n",
    "        \n",
    "        # FAQ results\n",
    "        ax[i, j].errorbar(\n",
    "            q_faq.prop_budget * N_QUESTIONS, q_faq.mean_width, \n",
    "            yerr=q_faq.mean_width_serr, marker=\"o\", \n",
    "            capsize=MARKERSIZE, capthick=1.0, color=colors[0])\n",
    "            \n",
    "        # Best baseline results\n",
    "        ax[i, j].errorbar(\n",
    "            q_baseline.prop_budget * N_QUESTIONS, q_baseline.mean_width, \n",
    "            yerr=q_baseline.mean_width_serr, marker=\"x\", \n",
    "            capsize=MARKERSIZE, capthick=1.0, color=colors[1])\n",
    "        \n",
    "        # uniform results\n",
    "        ax[i, j].errorbar(\n",
    "            q_uniform.prop_budget * N_QUESTIONS, q_uniform.mean_width, \n",
    "            yerr=q_uniform.mean_width_serr, marker=\"^\", \n",
    "            capsize=MARKERSIZE, capthick=1.0, color=colors[2])\n",
    "        \n",
    "# custom legend\n",
    "handles = [\n",
    "    Line2D([], [], marker=\"o\", color=colors[0], label=\"FAQ\"),\n",
    "    Line2D([], [], marker=\"x\", color=colors[1], label=\"Best Baseline Per Budget\"),\n",
    "    Line2D([], [], marker=\"^\", color=colors[2], label=\"Uniform\")\n",
    "]\n",
    "fig.legend(handles=handles, ncol=4, loc=\"lower center\", bbox_to_anchor=(0.5, -0.07))\n",
    "\n",
    "# beautify\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"appendix_figures/3_width_all-settings_both-datasets.pdf\", facecolor=\"white\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac68b371",
   "metadata": {},
   "source": [
    "# Coverage vs. model release date / accuracy on MMLU-Pro @ 7.5%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76525dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the logs for coverage-specific analysis\n",
    "coverage_logs = pd.concat(\n",
    "    [pd.read_csv(f\"logs/coverage_analysis/{f}\") \n",
    "     for f in os.listdir(\"logs/coverage_analysis\") if \".csv\" in f\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db27f89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Does coverage change depending on the model (e.g., its accuracy / when it was released?)\n",
    "    - Important because we could have overall coverage, but the coverage decays with temporal drift ...\n",
    "    - Let's put 7.5% as a representative example in main text, remainder in Appendix for transparency.\n",
    "    - Let's do it by release date and by actual accuracy. Use bbh+gpqa+ifeval+math+musr\n",
    "    \n",
    "*To clean up plot:\n",
    "1. Let's do K=501 k-NN by release date (left) and model accuracy (right)\n",
    "2. Set kernel to K / 6 to have ~99% mass within +/- 3 SD.\n",
    "'''\n",
    "# how many seeds do we have? Dataset for the appendix complementary figure.\n",
    "N_SEEDS, prop_budget, dataset = 100, 0.075, \"mmlu-pro\"\n",
    "\n",
    "# choose nearest-K and the Gaussian window std (in \"points\", not x-units)\n",
    "K = 501\n",
    "MIN_PERIODS = 30\n",
    "GAUSS_STD = K / 6 # want ~99% mass within +/- 3 std inside the K window, general rule of thumb.\n",
    "\n",
    "# load in the extra data that we need (just M2)\n",
    "M2 = pd.read_csv(f\"data/processed/{dataset}/M2.csv\")\n",
    "M2.created_date = pd.to_datetime(M2.created_date)\n",
    "\n",
    "# create our figure\n",
    "fig, ax = plt.subplots(1, 2, dpi=400, figsize=(6.5, 2.0), sharey=True)\n",
    "\n",
    "#### BY RELEASE DATE\n",
    "\n",
    "# beautify the subplot\n",
    "ax[0].grid(); ax[0].set_title(\"Per-Model Coverage vs. Model Release Date\")\n",
    "ax[0].set_xlabel(\"Model Release Date\")\n",
    "\n",
    "coverages = coverage_logs.query(\n",
    "    f\"dataset == '{dataset}' and prop_budget == {prop_budget}\"\n",
    ").iloc[:,3:].dropna(axis=1).to_numpy()\n",
    "\n",
    "# precompute the coverages (avg of 100 0-1 numbers)\n",
    "per_model_cov = coverages.mean(axis=0)\n",
    "\n",
    "# raw scatter plot results of the 2.2K numbers.\n",
    "ax[0].scatter(x=M2.created_date.values, y=per_model_cov, color=\"grey\", alpha=0.2, s=MARKERSIZE)\n",
    "\n",
    "# do Gaussian-weighted K-nearest-neighbors smoothing by release date.\n",
    "df = pd.DataFrame({\"created_date\": M2.created_date, \"coverage\": per_model_cov})\n",
    "df = df.sort_values(\"created_date\").set_index(\"created_date\")\n",
    "roll = df[\"coverage\"].rolling(window=K, win_type=\"gaussian\", center=True, min_periods=MIN_PERIODS)\n",
    "\n",
    "# need to compute standard deviations via moments (i.e., sqrt of variance)\n",
    "Ey  = roll.mean(std=GAUSS_STD) # this mean here is weighted mean, with weighting by Gaussian weights.\n",
    "Ey2 = (df[\"coverage\"]**2).rolling(\n",
    "    window=K, win_type=\"gaussian\", center=True, min_periods=MIN_PERIODS\n",
    ").mean(std=GAUSS_STD)\n",
    "\n",
    "# compute the standard deviation.\n",
    "sd = np.sqrt((Ey2 - Ey**2).clip(lower=0.0))\n",
    "\n",
    "# store our moving average (gaussian-smoothed) as a dataframe\n",
    "mov_avg = pd.DataFrame({\"mean\": Ey, \"sd\": sd})\n",
    "\n",
    "# plot the mean line + a \\pm 1 SD band.\n",
    "ax[0].plot(mov_avg.index, mov_avg[\"mean\"], linewidth=1.5, zorder=3)\n",
    "ax[0].fill_between(\n",
    "    mov_avg.index,\n",
    "    mov_avg[\"mean\"] - mov_avg[\"sd\"],\n",
    "    mov_avg[\"mean\"] + mov_avg[\"sd\"],\n",
    "    alpha=0.2, zorder=1)\n",
    "\n",
    "# beautify a bit more.\n",
    "ax[0].set_xticks([pd.Timestamp(2025, 1, 1), pd.Timestamp(2025, 2, 1), pd.Timestamp(2025, 3, 1)])\n",
    "ax[0].set_ylabel(\"Coverage (Per Model)\")\n",
    "\n",
    "#### BY TEST ACCURACY\n",
    "\n",
    "# beautify the subplot\n",
    "ax[1].grid(); ax[1].set_title(\"Per-Model Coverage vs. Model Accuracy\")\n",
    "ax[1].set_xlabel(\"Model Accuracy\")\n",
    "\n",
    "# compute the true accuracies per M2 model.\n",
    "mus_M2 = M2.iloc[:,3:].mean(axis=1).values\n",
    "acc_order = np.argsort(mus_M2)\n",
    "\n",
    "# sort the coverages by increasing true accuracy\n",
    "sorted_acc = mus_M2[acc_order]\n",
    "sorted_model_coverages = per_model_cov[acc_order]\n",
    "\n",
    "# scatter plot the raw coverages in high opacity.\n",
    "ax[1].scatter(sorted_acc, sorted_model_coverages, color=\"grey\", alpha=0.2, s=MARKERSIZE)\n",
    "\n",
    "# do Gaussian-weighted K-nearest-neighbors smoothing by model accuracy\n",
    "df = pd.DataFrame({\"acc\": sorted_acc, \"coverage\": sorted_model_coverages})\n",
    "df = df.sort_values(\"acc\").set_index(\"acc\")\n",
    "roll = df[\"coverage\"].rolling(window=K, win_type=\"gaussian\", center=True, min_periods=MIN_PERIODS)\n",
    "\n",
    "# compute the standard deviation via moment formula (same as above)\n",
    "Ey  = roll.mean(std=GAUSS_STD)\n",
    "Ey2 = (df[\"coverage\"]**2).rolling(\n",
    "    window=K, win_type=\"gaussian\", center=True, min_periods=MIN_PERIODS\n",
    ").mean(std=GAUSS_STD)\n",
    "sd = np.sqrt((Ey2 - Ey**2).clip(lower=0.0))\n",
    "\n",
    "# store our moving average (gaussian-smoothed) as a dataframe\n",
    "mov_avg = pd.DataFrame({\"mean\": Ey, \"sd\": sd})\n",
    "\n",
    "# plot the mean line + a \\pm 1 SD band.\n",
    "ax[1].plot(mov_avg.index, mov_avg[\"mean\"], linewidth=1.5, zorder=3)\n",
    "ax[1].fill_between(\n",
    "    mov_avg.index,\n",
    "    mov_avg[\"mean\"] - mov_avg[\"sd\"],\n",
    "    mov_avg[\"mean\"] + mov_avg[\"sd\"],\n",
    "    alpha=0.2, zorder=1)\n",
    "\n",
    "# beautify + save\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"appendix_figures/4_MMLU-pro_coverage-audits.pdf\", facecolor=\"white\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (Afterburner)",
   "language": "python",
   "name": "afterburner"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
